{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-ary-t/CA02---Naive-Bayes-/blob/main/CA02_NB_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below only if you're using **Google Colab** to run this notebook.\n",
        "\n",
        "- Put the data folders and this notebook in the same Google Drive Folder\n",
        "- This code allows us to pull folders & files from our Google Drive\n",
        "- Change the '/content/drive/MyDrive/Spring 2026/BSAN 6070 - Into to Machine Learning/Assignments/Coding Assignments/Data' to the path of the folder where your data folders and this notebook are saved, because Colab's default path is '/content'"
      ],
      "metadata": {
        "id": "Nbbd4Fx000gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/Spring 2026/BSAN 6070 - Into to Machine Learning/Assignments/Coding Assignments/Data'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgmoaoJYZnMv",
        "outputId": "5cba069a-a559-4081-e150-7b8721f33fc3",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Spring 2026/BSAN 6070 - Into to Machine Learning/Assignments/Coding Assignments/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ePHHdGlR01xV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZYXwtCsL_y"
      },
      "source": [
        "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm.\n",
        "\n",
        "In this assignment you will ...\n",
        "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
        "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
        "\n",
        "IMPORTANT NOTE:\n",
        "\n",
        "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zaQvV3c5RgKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Library Explanation**\n",
        "- os is use for interacting with the operating systems to work with files and directories\n",
        "- numpy is used for numerical computing like mathematical computation and fast array and matrix operations\n",
        "- Counter is used for count occurrences of items in a list, string, or other iterables\n",
        "- GaussianNB is a Gaussian Naive Bayes classifier\n",
        "- accuracy_score is a function that calculates how accurate a classifier is"
      ],
      "metadata": {
        "id": "1L6IavavQqQ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Import all other necessary libraries. Your code below ...\n",
        "#\n",
        "#\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Nt6-qkTtR3pV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**def make_Dictionary(root_dir)**\n",
        "- Creating a function call make_Dictionary that takes in as input  'root_dir', which is the folder/files that will be used.\n",
        "- The function first creates the variable 'all_words', which is an empty list that will be used in a 'for' loop later in the function, and the variable 'emails'.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**'emails'**\n",
        "- os.listdir() is a function that returns a list of the names of files and folders inside a directory.\n",
        "- os.path.join() is a function used to safely combine file and folder names into a single path.\n",
        "- 'emails' takes every file/folder name in 'root_dir', loops over each entry name, combines 'root_dir' with f to create a full path, and then collects all those full paths into a list and assigns it to emails.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**1st 'for' loop**\n",
        "- takes each item in the 'emails' list, opens the item, reads it line by line, splits each line into words, and then appends each word into the empty list created at the beginning of the function called 'all_words'.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "- Then after the loop is finished, the variable 'dictionary' is created using Counter to make a frequency map of all the words in the 'all_words' list that takes each unique word in the list and the count of how many times it appears in the list (i.e. {word: count, ...}.)\n",
        "- The variable 'list_to_remove' is then created by making a list of the unique words in the variable 'dictionary' and will be used in the next 'for' loop\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**2nd 'for' loop**\n",
        "- takes each word in the 'list_to_remove' list and removes the word from our 'dictionary' variable if\n",
        "  - there is a non-alphabetic character in the word\n",
        "  \n",
        "  or\n",
        "\n",
        "  - if the length of the word is 1 character long.\n",
        "- After those removals, the 'dictionary' variable is then limited to the 3,000 most common words.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Result**\n",
        "- The \"make_Dictionary\" function returns a list with the most common 3,000 words from the files/folders of emails it is given as a (word, freuqency) pair."
      ],
      "metadata": {
        "id": "-dcBwVxaPkEh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KY-Lsi5dcGja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**def extract_features(mail_dir)**\n",
        "\n",
        "*   Creating a function called extract_features that takes in mail_dir, which is the directory containing the email files (training or testing).\n",
        "*  The goal of this function is to convert each email into a numerical feature vector based on the previously created dictionary, and generate labels indication whethere an email is a spam or not.\n",
        "\n",
        "\n",
        "---\n",
        "**files**\n",
        "\n",
        "\n",
        "*   os.listdir(mail_dir) returns a list of file names inside the given directory.\n",
        "*  os.path.join(mail_dir, fi) safely combines the directory path with each file name.\n",
        "\n",
        "\n",
        "*   files becomes a list of full file paths for all emails inside mail_dir.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Feature matrix and labels initialization**\n",
        "\n",
        "\n",
        "*  *features_matrix = np.zeros((len(files), 3000)):* Creates a matrix filled with zeros. Each row represents one email. Each column represents one word from the 3,000-word dictionary.\n",
        "* *train_labels = np.zeros(len(files)):* Creates an array to store labels for each email. A value of 0 represents non-spam, and 1 represents spam.\n",
        "\n",
        "\n",
        "---\n",
        "**Counters**\n",
        "\n",
        "\n",
        "*   count = 1 tracks progress (not essential to the final output).\n",
        "*   docID = 0 is the row index for the current email in features_matrix.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Loop through emails**\n",
        "\n",
        "\n",
        "\n",
        "*   for fil in files: goes through each email file.\n",
        "*   with open(fil) as fi: opens the file safely.\n",
        "\n",
        "\n",
        "*  for i, line in enumerate(fi): loops through each line with its line number.\n",
        "*   if i == 2: only processes the 3rd line (the message content).\n",
        "\n",
        "\n",
        "---\n",
        "**Build word-frequency features**\n",
        "\n",
        "\n",
        "\n",
        "*   words = line.split() splits the message into words.\n",
        "*   For each word, the code searches for it in dictionary:\n",
        "\n",
        "\n",
        "    1. If found, it sets the correct column (wordID) and stores how many times it appears:\n",
        "       2.   features_matrix[docID, wordID] = words.count(word)\n",
        "\n",
        "\n",
        "---\n",
        "**Assign spam label from filename**\n",
        "\n",
        "\n",
        "*   Starts with train_labels[docID] = 0 (non-spam).\n",
        "*   Gets the filename using fil.split('/') and lastToken = ...[-1].\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Move to next email**\n",
        "\n",
        "\n",
        "\n",
        "*   count = count + 1 increments progress counter.\n",
        "*  docID = docID + 1 moves to the next row in the feature matrix.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Result**\n",
        "\n",
        "\n",
        "\n",
        "*   features_matrix = word-count vectors for each email\n",
        "*   train_labels = 0 (not spam) or 1 (spam)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k5KRg9vTk8O8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "zoq-rE7Mx0pp",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
        "# for example: TRAIN_DIR = '../../train-mails'\n",
        "#              TEST_DIR = '../../test-mails'\n",
        "\n",
        "TEST_DIR = './test-mails'\n",
        "TRAIN_DIR = './train-mails'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**'dictionary'**\n",
        "- takes the training data and puts it through the 'make_dictionary' function created to return a dictionary of the 3,000 most common words in the test data\n",
        "\n",
        "---\n",
        "\n",
        "- Takes the training data and puts it into the extract_features function, which will return 1.) a matrix with each row representing a file/email in the test data, and the columns representing the most common 3,000 words in all the emails, 2.) a vector for each email stating whether it is spam (1) or not (0)\n",
        "\n",
        "- Does the same as above with the testing data"
      ],
      "metadata": {
        "id": "6ZbFOR027SAV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134lmhauyQxE",
        "outputId": "a8294747-96b0-484c-f820-4af38971e48a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n"
          ]
        }
      ],
      "source": [
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "92oaZXheCRas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trained Model**\n",
        "- Trains a model using Gaussian Naive Bayes classification on the matrix and its corresponding label vector (whether the email is spam or not) of the test data.\n",
        "- Takes the matrix of the test data and uses the trained model to predict the label vector of each email in the test data (whether the email is spam or not)\n",
        "- Calculates the accuracy of the model by comparing the true/correct classification vector of the test data to the predicted vector from the model\n",
        "\n",
        "**Sources**\n",
        "- Utilized Google Copilot to determine what packages and funcitons were needed to run a Gaussian Naive Bayes classification algorithm."
      ],
      "metadata": {
        "id": "BY2b2gQo6zDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "nb = GaussianNB()\n",
        "nb.fit(features_matrix, labels)\n",
        "print(\"Training completed\")\n",
        "\n",
        "print(\"testing trained model to predict Test Data labels\")\n",
        "pred = nb.predict(test_features_matrix)\n",
        "print(\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "\n",
        "acc = accuracy_score(test_labels, pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10FNuonJ6sz8",
        "outputId": "82357d26-a9a1-4968-8017-7e21128ed6db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Professor's Correct Output**"
      ],
      "metadata": {
        "id": "20llMXkwf5dO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9",
        "id": "cUuoOM56Zj1A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9653846153846154\n"
          ]
        }
      ],
      "source": [
        "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
        "# Your code below ...\n",
        "# Your output should look like below if your code is right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}